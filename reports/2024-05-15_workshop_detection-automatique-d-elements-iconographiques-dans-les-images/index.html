<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="../../sunset.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link href="../../_app/immutable/assets/0.D0TAEvq0.css" rel="stylesheet">
		<link rel="modulepreload" href="../../_app/immutable/entry/start.DkMwbYQ7.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/D-FGJHsZ.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/CXCHmQ-B.js">
		<link rel="modulepreload" href="../../_app/immutable/entry/app.DGln3RUe.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/C1FmrZbK.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/DuaWf0Pd.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/0.BPmGZcOY.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/hLqZeU-6.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/7.BTHH_Nau.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/BheWnx7M.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/D2-NGLRx.js"><!-- HEAD_svelte-1i32evn_START --><!-- HEAD_svelte-1i32evn_END -->
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">     <div class="content">  <nav class="svelte-epptjw"> <a href="/" class="svelte-epptjw" data-svelte-h="svelte-4ebbsj"><h1 class="svelte-epptjw">/log</h1></a> <ul class="svelte-epptjw"><li><a href="/reports" class="svelte-epptjw active" data-svelte-h="svelte-12wekpw">Comptes rendus</a></li> <li><a href="/notes" class="svelte-epptjw" data-svelte-h="svelte-eu7epz">Notes</a></li> <li><a href="/projets" class="svelte-epptjw" data-svelte-h="svelte-4lv15p">Projets</a></li>  <li><button class="switch svelte-epptjw" role="switch" aria-checked="true"></button></li></ul></nav>   <main>  <article><p class="date">15 mai 2024</p> <p class="speaker">Christopher Kermorvant ; Marion Charpier</p> <h1 data-svelte-h="svelte-bizbi1">Détection automatique d’éléments iconographiques dans les images : principes et mise en œuvre</h1> <p data-svelte-h="svelte-ppjvy2">3 types de modèle</p> <ul data-svelte-h="svelte-qg0rhc"><li>détection, c’est le moins fin, il n’est pas nécessaire de créer une ontologie, on cherche des objets, sans avoir besoin de les classifier</li> <li>classification : on attribut une étiquette ou une classe à une image ou à une région spécifique de l’image</li> <li>segmentation : encore plus fin, on divise une image en segment ou en région en fonction de certaine propriété</li></ul> <p data-svelte-h="svelte-f3t21x">En utilisant SAM on peut segmenter une image, récupérer les coordonées et s’en servir pour les classifier.
La robustesse d’un modèle est calculer avec un metric l’<em>intersection over union</em> (IOU). Il s’agit du taux de chevauchement entre la boite d’annotation et la vérité de terrain. En dessous de 0.5 (50% de superposition des deux boites) on considère que la prédiction est fausse. Mais attention :</p> <ul data-svelte-h="svelte-1twb72a"><li>vrai positif (TP) : un objet dont la classe et la detection sont bonnes</li> <li>faux positif (FP) : détection d’une classe correcte mais mal positionné</li> <li>faux négatif (FN) : rien n’est bon dans la détection</li></ul> <p data-svelte-h="svelte-1is5ms8">ces trois indicateurs permettent de calculer le rappel, la précision et le score F1
Un modèle parfait à une score F1 = 1.</p> <p data-svelte-h="svelte-1l75oaj">Une autre metric intéressante pour évaluer un modèle est la matrice de confusion.</p> <h2 data-svelte-h="svelte-1qdm1n2">Comment choisir un modèle</h2> <p data-svelte-h="svelte-rhl8d5">Prendre en compte précision et performance, complexité et taille du modèle (demande de ressources computationnelles), robustesse aux variations, flexibilité et modularité.</p> <h2 data-svelte-h="svelte-tjj8i">Détection automatique d’objets dans les images avec YOLO</h2> <h3 data-svelte-h="svelte-1ris6ax">Principe de l’apprentissage automatique (Machine learning)</h3> <p data-svelte-h="svelte-7j1n5l">Comment faire exécuter une tâche à un ordinateur
La première solution c’est d’écrire un programme : un expert explique à un développeur la tâche à réaliser.</p> <p data-svelte-h="svelte-1up2ao7">La seconde solution c’est de faire apprendre la machine : avec le ML on a toujours un expert qui prend des exemples annotés, un ingénieur ML va nourrir un apprentissage à partir des exemples annotés pour créer un modèle, qui sera capable de rédiger un programme.</p> <p data-svelte-h="svelte-d2e8f4">avec la programmation
le programme est écrit par un dev, l’expert doit pouvoir explicité les règles, il faut un programme par tâche, en cas d’erreur il faut modifier le programme
Avec l’apprentissage automatique, le programme est écrit par la machine, l’expert doit annoter des exemple, un seul programme d’apprentissage pour plusieurs tâche et si on a des erreurs, il suffit de donner de nouveaux exemples.
le pipeline est le suivant :</p> <pre class="language-undefined"><!-- HTML_TAG_START --><code class="language-undefined">Exemples annotés -&gt;     apprentissage -&gt;     modèle
                                                ↓
                   Exemples à traiter -&gt;     programme -&gt;     exécution -&gt;     prédiction</code><!-- HTML_TAG_END --></pre> <p data-svelte-h="svelte-o116q2">Les exemples définissent le programme : l’annotation est la phse la plus importante.
Comment bien choisir les exemple : il faut constituer un échantillonage aléatoire et représentatif. Il faut également annoter come ce que l’on souhaite obtenir en prédiction.</p> <p data-svelte-h="svelte-1l761bw">L’objectif est d’apprendre à généraliser pour prédire sur des exemples nons vus pendant l’apprentissage. : il faut 3 éléments</p> <ul data-svelte-h="svelte-10hg1hn"><li>un échantillon pour apprendre (train test)</li> <li>un echantillon pour vérifier le modèle généralisé (validation set)</li> <li>un échantillon pour évaluer le modèle (test set)
Ces 3 ensembles doivent être repésentatifs, aléatoires et disjoints.</li></ul> <p data-svelte-h="svelte-wgozb2">NB : avec YOLO assez peu de données sont nécessaires pour obtenir de bon résultat.
+NB 2 : possibilité d’augmenter artificiellement les données avec les changements de perspectives par exemple, ou modification des images. mais plus efficace lorsque c’est intégrer dans un script d’apprentissage.</p> <h2 data-svelte-h="svelte-15qhvvw">Entrainement d’un modèle de détection avec Arkindex</h2> <ul data-svelte-h="svelte-18adcol"><li><a href="https://doc.arkindex.org/tutorial/segmentation-training/" rel="nofollow">Documentation Arkindex</a></li> <li><a href="https://notes.teklia.com/s/P6wnIUYqQ#" rel="nofollow">notes Teklia</a></li></ul> <p data-svelte-h="svelte-r5gpgr"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/4832afb3-38d8-4ee0-8554-1a00f1b619fd.png" alt="img"></p> <h3 data-svelte-h="svelte-7ksp00">1. Créer des répertoires (folders) dans votre projet</h3> <ul data-svelte-h="svelte-1uhlixa"><li>Naviguer dans votre projet</li> <li>Créer 3 répertoires (folders) avec les noms Train, Dev et Test</li> <li>Menu Actions-&gt;Add folder</li></ul> <p data-svelte-h="svelte-urq9fw"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/caf6c560-0e42-4867-ae8b-f811a3b0c083.png" alt="img"></p> <h4 data-svelte-h="svelte-3muh7o">En vidéo :</h4> <p data-svelte-h="svelte-18jbdu0">youtube S_7N3jYALtc</p> <h3 data-svelte-h="svelte-13yms47">2. Répartir les exemples aléatoirement dans les répertoires train/dev/test</h3> <p data-svelte-h="svelte-f9855y">2.1 Utiliser la présentation Random</p> <p data-svelte-h="svelte-1swh59k"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/21161b4f-8ae3-4fd4-a2ad-27d91b0e3d01.png" alt="img"></p> <p data-svelte-h="svelte-1u8xq5p">2.2 Utiliser la pagination à 100</p> <p data-svelte-h="svelte-2pcjbu"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/c4600678-8f4d-45ea-add1-c0eb84c35bf2.png" alt="img"></p> <p data-svelte-h="svelte-u97qap">2.3 Utiliser la sélection</p> <p data-svelte-h="svelte-1459c16"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/a2e9731c-8aac-40fd-bb58-73bd32ad2af8.png" alt="img"></p> <h4 data-svelte-h="svelte-3muh7o">En vidéo :</h4> <p data-svelte-h="svelte-1379fmq">youtube XOP27j-4ee4</p> <h3 data-svelte-h="svelte-1nf8hgq">3. Créer un dataset avec des sous-ensembles Train/Val/Test</h3> <ul data-svelte-h="svelte-1xb9zca"><li>Menu Actions -&gt; Project Information -&gt; Dataset</li></ul> <p data-svelte-h="svelte-dnbpqs"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/06924b36-4c38-4cf1-a6d3-ccc116b8beea.png" alt="img"></p> <h4 data-svelte-h="svelte-3muh7o">En vidéo :</h4> <p data-svelte-h="svelte-1skaa8m">youtube wkxgt9NSMXc</p> <h4 data-svelte-h="svelte-1br4t9w">4. Générer l’export complet du projet</h4> <ul data-svelte-h="svelte-1dtp1ml"><li>Menu Actions -&gt; Manage Export -&gt; Start Export
<img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/adf1b4cf-527e-4a3e-8f83-6076d429adbd.png" alt="img"></li></ul> <p data-svelte-h="svelte-1joh6n1">:::info
Pourquoi cette étape ?
Arkindex permet l’entrainement distribué (cloud, cluster)
L’export et la génération de l’archive d’entrainement permettent la distribution des données
:::</p> <h4 data-svelte-h="svelte-3muh7o">En vidéo :</h4> <p data-svelte-h="svelte-1t7zxyr">youtube w082mRvSqEI</p> <h3 data-svelte-h="svelte-8otvjo">5. Générer l’archive d’entrainement à partir du projet</h3> <ul data-svelte-h="svelte-1qfjvx7"><li>Menu Actions -&gt; Create Dataset process</li></ul> <p data-svelte-h="svelte-z4fnco"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/a2ad2b26-7226-45f1-a05f-97cd95166fc2.png" alt="img"></p> <ul data-svelte-h="svelte-1xqgdd2"><li>Select « Generic  Training Dataset Extractor »</li></ul> <p data-svelte-h="svelte-jdcsk5"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/24cd7a48-3d19-48a2-9df4-9b9818ecd8f4.png" alt="img"></p> <ul data-svelte-h="svelte-8phdo9"><li>Run Process</li></ul> <p data-svelte-h="svelte-1a45yh2"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/50b131b8-9bed-46a0-884f-504505173939.png" alt="img"></p> <h4 data-svelte-h="svelte-3muh7o">En vidéo :</h4> <p data-svelte-h="svelte-1nfkn94">youtube GLOY-Q9ekpc</p> <h3 data-svelte-h="svelte-xjqcz5">6. Créer un modèle</h3> <ul data-svelte-h="svelte-ofti6r"><li>Menu Personnel -&gt; Models</li></ul> <p data-svelte-h="svelte-j6fs0l"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/bce1c379-75e1-44c0-abae-5c5d3540b971.png" alt="img"></p> <ul data-svelte-h="svelte-1ruwlcw"><li>CREATE MODEL puis renseigner les informations</li></ul> <p data-svelte-h="svelte-syvn23"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/98471c27-be6c-406c-a396-2c1b0ae067cf.png" alt="img"></p> <h4 data-svelte-h="svelte-3muh7o">En vidéo :</h4> <p data-svelte-h="svelte-13umhos">youtube _0B2ARsnbqo</p> <h3 data-svelte-h="svelte-r13kbi">7. Lancer l’entrainement du modèle YOLO</h3> <p data-svelte-h="svelte-19jf8q8">7.1 Menu Actions -&gt; Create Dataset process</p> <p data-svelte-h="svelte-1gc4vl3"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/3b52d35e-166c-41e3-8515-a00802688e2b.png" alt="img"></p> <p data-svelte-h="svelte-1s56nez">7.2. Find the YOLO Training | Detect/Segment worker</p> <p data-svelte-h="svelte-1hpai6s"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/f7cf0df5-655f-424f-b7b6-4c1a18c32b55.png" alt="img"></p> <p data-svelte-h="svelte-14mqkwi">7.3 Créer une configuration d’entrainement</p> <ul data-svelte-h="svelte-13u754r"><li>Name : votre_nom YOLO illustration</li> <li>Class names to predict : illustration</li> <li>Model that will receive the new trained version :  nom du modèle créé en 6.</li> <li>Number of epochs to train the model : 3</li> <li>Type of object to detect using the segmenter : bbox</li></ul> <p data-svelte-h="svelte-pydog1"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/35a7e5b6-efc6-4a1a-8c93-ac1f68b2dbdd.png" alt="img"></p> <p data-svelte-h="svelte-qximtf">7.4 Lancer l’entrainement</p> <ul data-svelte-h="svelte-64yn2t"><li>Sélectionner GPU</li> <li>RUN PROCESS</li></ul> <p data-svelte-h="svelte-1w6zbgo"><img src="https://storage.teklia.com/tools-hedgedoc-uploads/uploads/e0b0c9ef-2ed6-476e-8256-83c8c26f5b26.png" alt="img"></p> <h4 data-svelte-h="svelte-3muh7o">En vidéo :</h4> <p data-svelte-h="svelte-1wxtka3">youtube 9XiL9FxD31M</p></article></main>   <footer class="svelte-1capoi1" data-svelte-h="svelte-1h3xx8c"><nav><ul class="svelte-1capoi1"><li><a href="https://github.com/sardinecan/log" class="svelte-1capoi1">Github</a></li> </ul></nav></footer> </div> 
			
			<script>
				{
					__sveltekit_tndzjx = {
						base: new URL("../..", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("../../_app/immutable/entry/start.DkMwbYQ7.js"),
						import("../../_app/immutable/entry/app.DGln3RUe.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 7],
							data: [null,null],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
